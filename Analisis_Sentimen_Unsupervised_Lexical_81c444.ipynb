{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 6626359,
          "sourceType": "datasetVersion",
          "datasetId": 3825301
        },
        {
          "sourceId": 6680696,
          "sourceType": "datasetVersion",
          "datasetId": 3853862
        },
        {
          "sourceId": 6680948,
          "sourceType": "datasetVersion",
          "datasetId": 3853767
        },
        {
          "sourceId": 6681733,
          "sourceType": "datasetVersion",
          "datasetId": 3854509
        }
      ],
      "dockerImageVersionId": 30558,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Analisis Sentimen - Unsupervised Lexical 81c444",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OtnielDegei/Festival-Danau-Paniai.Github.io/blob/main/Analisis_Sentimen_Unsupervised_Lexical_81c444.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "rizkia14_nlp_bahasa_resources_path = kagglehub.dataset_download('rizkia14/nlp-bahasa-resources')\n",
        "rizkia14_pln_mobile_path = kagglehub.dataset_download('rizkia14/pln-mobile')\n",
        "rizkia14_kamus_sentimen_path = kagglehub.dataset_download('rizkia14/kamus-sentimen')\n",
        "rizkia14_movie_review_path = kagglehub.dataset_download('rizkia14/movie-review')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "7i3ARjEDhdJE"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pendahuluan\n",
        "\n",
        "![](https://static1.squarespace.com/static/5daddb33ee92bf44231c2fef/t/5f0387d2f6724b5987a29311/1594066902743/natural%2Blanguage%2Bprocessing%2Bin%2Bhealthcare%2B-%2Bforesee%2Bmedical.gif?format=1500w)\n",
        "![](https://miro.medium.com/proxy/1*_JW1JaMpK_fVGld8pd1_JQ.gif)\n",
        "\n",
        "\n",
        "Analisis sentimen adalah proses untuk mengidentifikasi, mengekstrak, dan mengevaluasi opini, perasaan, atau sentimen yang terkandung dalam teks, seperti doc pelanggan, posting media sosial, artikel berita, atau teks lainnya. Tujuan utama dari analisis sentimen adalah untuk memahami apakah suatu teks mengandung sentimen positif, negatif, atau netral, serta sejauh mana sentimen tersebut diekspresikan.\n",
        "\n",
        "Terdapat beberapa metode untuk melakukan analisis sentimen, termasuk:\n",
        "* Pendekatan berbasis aturan: Menggunakan aturan atau daftar kata kunci untuk menilai sentimen teks.\n",
        "* Pendekatan berbasis statistik: Menggunakan teknik seperti analisis regresi logistik atau mesin pembelajaran untuk mengklasifikasikan teks.\n",
        "* Pembelajaran Mendalam (Deep Learning): Memanfaatkan jaringan saraf tiruan (neural networks) untuk analisis sentimen yang lebih kompleks.\n",
        "\n",
        "Data untuk analisis sentimen dapat diperoleh dari berbagai sumber, seperti doc pelanggan, media sosial, survei, atau wawancara. Setiap sumber data mungkin memiliki karakteristik dan tantangan tersendiri."
      ],
      "metadata": {
        "id": "aPHN1drXhdJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsupervised Lexical Based Models\n",
        "\n",
        "Unsupervised lexical models, dalam konteks analisis sentimen, adalah jenis model yang digunakan untuk mengidentifikasi dan menganalisis sentimen dalam teks tanpa memerlukan anotasi atau label sentimen pada data pelatihan. Model ini bergantung pada informasi leksikal atau fitur-fitur linguistik yang ditemukan dalam teks untuk menentukan sentimen positif, negatif, atau netral.\n",
        "\n",
        "Model leksikon biasanya menggunakan leksikon, juga dikenal sebagai kamus atau kosa kata kata-kata yang secara khusus terkait dengan analisis sentimen. Leksikon ini berisi daftar kata-kata yang terkait dengan sentimen positif dan negatif, polaritas (besaran nilai negatif atau positif), part of speech (POS) tagging, pengklasifikasi subjektivitas (kuat, lemah, netral), suasana hati, dan sebagainya. Kita dapat menggunakan leksikon-leksikon ini dan menghitung sentimen dari dokumen teks dengan mencocokkan kehadiran kata-kata tertentu dari leksikon dan kemudian mempertimbangkan faktor-faktor lain seperti keberadaan parameter negasi, kata-kata sekitar, konteks keseluruhan, frasa, dan nilai polaritas sentimen keseluruhan agregat untuk menentukan nilai sentimen akhir.\n",
        "\n",
        "\n",
        "Setiap kata dalam teks diberi bobot berdasarkan sejauh mana kata tersebut memiliki sentimen positif atau negatif menurut kamus sentimen. Bobot ini dapat diberikan dalam bentuk skor numerik.\n",
        "\n",
        "Model unsupervised akan mencoba mendeteksi pola kata atau frasa yang mengindikasikan sentimen. Contohnya, jika dalam sebuah teks terdapat kata-kata positif seperti \"baik\", \"senang\", dan \"puas\", serta kata-kata negatif seperti \"buruk\" dan \"kecewa\", model akan mencoba untuk mengekstrak sentimen berdasarkan keseimbangan antara kata-kata ini.\n",
        "\n",
        "Model akan menghitung skor sentimen keseluruhan berdasarkan pembobotan kata dan pola yang terdeteksi. Skor positif mengindikasikan sentimen positif, skor negatif mengindikasikan sentimen negatif, dan skor netral mengindikasikan ketiadaan sentimen."
      ],
      "metadata": {
        "id": "xdTEtZilhdJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cara paling sederhana memanfaatkan lexicon adalah dengan menghitung kata positif dan negatif dalam suatu kalimat kemudian menampilkan angka 1 (positif),0(netral) atau -1(negatif)\n",
        "\n",
        "$$\n",
        "\\text{StSc}(x) = \\Bigg \\{ \\begin{matrix}  1 &\n",
        "\\text{kata positif } > \\text{negatif} \\\\ -1 & \\text{kata positif } < \\text{negatif} \\\\ 0 & \\text{selainnya} \\end{matrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "xS9a8tLohdJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi Load Lexicon\n",
        "def loadLexicon(file):\n",
        "    df=open(file,\"r\",encoding=\"utf-8\", errors='replace')\n",
        "    data=df.readlines();df.close()\n",
        "    return [d.strip().lower() for d in data]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:15:01.417558Z",
          "iopub.execute_input": "2023-10-13T12:15:01.417934Z",
          "iopub.status.idle": "2023-10-13T12:15:01.455557Z",
          "shell.execute_reply.started": "2023-10-13T12:15:01.417905Z",
          "shell.execute_reply": "2023-10-13T12:15:01.45473Z"
        },
        "trusted": true,
        "id": "SwCKCDBXhdJR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "fpos = \"/kaggle/input/kamus-sentimen/s-pos.txt\"\n",
        "fneg = \"/kaggle/input/kamus-sentimen/s-neg.txt\"\n",
        "fnegasi = \"/kaggle/input/kamus-sentimen/negasi.txt\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:15:01.457061Z",
          "iopub.execute_input": "2023-10-13T12:15:01.45753Z",
          "iopub.status.idle": "2023-10-13T12:15:01.460873Z",
          "shell.execute_reply.started": "2023-10-13T12:15:01.457502Z",
          "shell.execute_reply": "2023-10-13T12:15:01.46022Z"
        },
        "trusted": true,
        "id": "0oqJadSGhdJS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "positif, negatif, negasi = loadLexicon(fpos), loadLexicon(fneg), loadLexicon(fnegasi)\n",
        "print(positif[:10])\n",
        "print(negatif[:10])\n",
        "print(negasi[:10])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:15:01.462069Z",
          "iopub.execute_input": "2023-10-13T12:15:01.462555Z",
          "iopub.status.idle": "2023-10-13T12:15:01.502556Z",
          "shell.execute_reply.started": "2023-10-13T12:15:01.462529Z",
          "shell.execute_reply": "2023-10-13T12:15:01.501756Z"
        },
        "trusted": true,
        "id": "DFKillK0hdJT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def prediksiSentiment(kalimat, positif, negatif, negasi):\n",
        "    posWords = []\n",
        "    negWords = [w for w in negatif if w in kalimat]\n",
        "    for w in positif:\n",
        "        if w in kalimat:\n",
        "            negated = False\n",
        "            for n in negasi:\n",
        "                if n+' '+w in kalimat:\n",
        "                    negWords.append(n+' '+w)\n",
        "                    negated = True\n",
        "                    break\n",
        "            if not negated:\n",
        "                posWords.append(w)\n",
        "    nPos, nNeg = len(posWords), len(negWords)\n",
        "    if nPos>nNeg:\n",
        "        return 1\n",
        "    if nPos<nNeg:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:15:01.505628Z",
          "iopub.execute_input": "2023-10-13T12:15:01.506354Z",
          "iopub.status.idle": "2023-10-13T12:15:01.51398Z",
          "shell.execute_reply.started": "2023-10-13T12:15:01.506311Z",
          "shell.execute_reply": "2023-10-13T12:15:01.512756Z"
        },
        "trusted": true,
        "id": "lt4hzbsUhdJT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Teks = \"mie ayam ini enak\"\n",
        "prediksiSentiment(Teks, positif, negatif, negasi)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:15:01.51579Z",
          "iopub.execute_input": "2023-10-13T12:15:01.516516Z",
          "iopub.status.idle": "2023-10-13T12:15:01.534466Z",
          "shell.execute_reply.started": "2023-10-13T12:15:01.516463Z",
          "shell.execute_reply": "2023-10-13T12:15:01.53329Z"
        },
        "trusted": true,
        "id": "MGcHHUbthdJU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Teks = \"dia tidak hadir di pelatihan\"\n",
        "prediksiSentiment(Teks, positif, negatif, negasi)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:15:01.535773Z",
          "iopub.execute_input": "2023-10-13T12:15:01.536089Z",
          "iopub.status.idle": "2023-10-13T12:15:01.554305Z",
          "shell.execute_reply.started": "2023-10-13T12:15:01.53606Z",
          "shell.execute_reply": "2023-10-13T12:15:01.553126Z"
        },
        "trusted": true,
        "id": "YxI8uGzhhdJV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Namun metode ini tidak bisa mendeteksi pernyataan seperti ini"
      ],
      "metadata": {
        "id": "iOLGOfULhdJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Teks = \"Ujiannya sangat sulit, aku tidak bisa mengerjakannya. Tapi bohong. Berchandyaaa\"\n",
        "prediksiSentiment(Teks, positif, negatif, negasi)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:15:01.556136Z",
          "iopub.execute_input": "2023-10-13T12:15:01.556579Z",
          "iopub.status.idle": "2023-10-13T12:15:01.572596Z",
          "shell.execute_reply.started": "2023-10-13T12:15:01.556538Z",
          "shell.execute_reply": "2023-10-13T12:15:01.571195Z"
        },
        "trusted": true,
        "id": "qRLz28mEhdJX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IndoBERT\n",
        "\n",
        "IndoBERT adalah model bahasa yang diadaptasi khusus untuk bahasa Indonesia. Ini merupakan versi dari BERT (Bidirectional Encoder Representations from Transformers) yang telah dilatih untuk memahami teks dalam bahasa Indonesia. Model ini sangat berguna dalam tugas analitik teks seperti pemahaman teks, pengklasifikasian sentimen, dan pemodelan bahasa, karena dapat menghasilkan representasi vektor teks yang kaya dan kontekstual.\n",
        "\n",
        "BERT adalah sebuah model bahasa yang revolusioner dalam pemrosesan bahasa alami (NLP). Model ini dikembangkan oleh Google AI pada tahun 2018. Berikut adalah beberapa poin kunci tentang BERT:\n",
        "\n",
        "* Model Bahasa: BERT adalah model bahasa yang mendalam berbasis transformer. Ini memiliki kemampuan untuk memahami konteks dan hubungan antara kata dalam teks dengan cara yang lebih baik daripada model sebelumnya.\n",
        "\n",
        "* Bidireksional: BERT memproses teks secara simultan dari kedua arah (disebut \"bidireksional\"), yang berarti ia dapat memahami kata-kata dalam konteks lengkap mereka dalam kalimat, bukan hanya dari kiri ke kanan atau sebaliknya. Ini memberikan pemahaman yang lebih baik tentang arti sebenarnya dari kata-kata dalam suatu konteks.\n",
        "\n",
        "* Pre-trained dan Fine-tuning: BERT dilatih terlebih dahulu pada korpus teks yang sangat besar, sehingga modelnya memahami banyak aspek bahasa. Kemudian, model BERT ini dapat di-tune ulang untuk tugas-tugas NLP tertentu, seperti pengklasifikasian teks, pemahaman teks, atau tugas-tugas terkait bahasa lainnya.\n",
        "\n",
        "* State-of-the-Art: Ketika BERT pertama kali diperkenalkan, itu mencapai hasil yang sangat baik dalam berbagai tugas pemrosesan bahasa alami dan sejak itu menjadi dasar bagi banyak perkembangan terbaru dalam NLP. Model-model berbasis BERT telah menjadi standar de facto untuk tugas-tugas NLP.\n",
        "\n",
        "* Open Source: Google merilis BERT sebagai perangkat sumber terbuka sehingga peneliti dan pengembang di seluruh dunia dapat menggunakannya dan melakukan fine-tuning sesuai dengan kebutuhan mereka."
      ],
      "metadata": {
        "id": "HWl_W5k2hdJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of Indobert\n",
        "\n",
        "Latihan kali ini akan melakukan analisis sentimen review pengguna aplikasi PLN Mobile. Referensi syntax milik [YosefOwenM-0905](https://github.com/YosefOwenM-0905/Implementation-Of-Indobert-On-UserReviewsOfThePlnMobile-Application-BasedOnIndonesianLanguageLexicon), digunakan untuk pembelajaran."
      ],
      "metadata": {
        "id": "ipkd4IhEhdJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "review = pd.read_csv('/kaggle/input/pln-mobile/review-pln-mobile.csv', sep=\",\")\n",
        "review"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:15:01.574108Z",
          "iopub.execute_input": "2023-10-13T12:15:01.574533Z",
          "iopub.status.idle": "2023-10-13T12:15:02.136988Z",
          "shell.execute_reply.started": "2023-10-13T12:15:01.574493Z",
          "shell.execute_reply": "2023-10-13T12:15:02.135727Z"
        },
        "trusted": true,
        "id": "mdzZPiF3hdJY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Pre-processing"
      ],
      "metadata": {
        "id": "i6ThHYB1hdJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nlp-id"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-10-13T12:15:02.138704Z",
          "iopub.execute_input": "2023-10-13T12:15:02.139237Z",
          "iopub.status.idle": "2023-10-13T12:16:08.198417Z",
          "shell.execute_reply.started": "2023-10-13T12:15:02.1392Z",
          "shell.execute_reply": "2023-10-13T12:16:08.197159Z"
        },
        "trusted": true,
        "id": "40mEfIfShdJY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import json\n",
        "from nlp_id.tokenizer import Tokenizer\n",
        "from nlp_id.stopword import StopWord\n",
        "from nlp_id.lemmatizer import Lemmatizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:16:08.203511Z",
          "iopub.execute_input": "2023-10-13T12:16:08.204826Z",
          "iopub.status.idle": "2023-10-13T12:16:09.838903Z",
          "shell.execute_reply.started": "2023-10-13T12:16:08.204783Z",
          "shell.execute_reply": "2023-10-13T12:16:09.837214Z"
        },
        "trusted": true,
        "id": "jws1GXJUhdJZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#import kamus bahasa baku\n",
        "with open('/kaggle/input/nlp-bahasa-resources/combined_slang_words.txt') as f:\n",
        "    data0 = f.read()\n",
        "print(\"Data type before reconstruction : \", type(data0))\n",
        "formal_indo = json.loads(data0)\n",
        "print(\"Data type after reconstruction : \", type(formal_indo))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:16:09.84065Z",
          "iopub.execute_input": "2023-10-13T12:16:09.842208Z",
          "iopub.status.idle": "2023-10-13T12:16:09.859456Z",
          "shell.execute_reply.started": "2023-10-13T12:16:09.842153Z",
          "shell.execute_reply": "2023-10-13T12:16:09.858224Z"
        },
        "trusted": true,
        "id": "DEPjuWyBhdJZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def informal_to_formal_indo(text):\n",
        "    res = \" \".join(formal_indo.get(ele, ele) for ele in text.split())\n",
        "    return(res)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:16:09.8612Z",
          "iopub.execute_input": "2023-10-13T12:16:09.862373Z",
          "iopub.status.idle": "2023-10-13T12:16:09.868463Z",
          "shell.execute_reply.started": "2023-10-13T12:16:09.862337Z",
          "shell.execute_reply": "2023-10-13T12:16:09.867656Z"
        },
        "trusted": true,
        "id": "5Cp_S4srhdJZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "stopword = StopWord()\n",
        "lemmatizer = Lemmatizer()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:16:09.869906Z",
          "iopub.execute_input": "2023-10-13T12:16:09.870818Z",
          "iopub.status.idle": "2023-10-13T12:16:11.903248Z",
          "shell.execute_reply.started": "2023-10-13T12:16:09.870777Z",
          "shell.execute_reply": "2023-10-13T12:16:11.901936Z"
        },
        "trusted": true,
        "id": "h1w91wrjhdJZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def my_tokenizer(doc):\n",
        "    doc = re.sub(r'@[A-Za-z0-9]+', '', doc)\n",
        "    doc = re.sub(r'#[A-Za-z0-9]+', '', doc)\n",
        "    doc = re.sub(r'RT[\\s]', '', doc)\n",
        "    doc = re.sub(r\"http\\S+\", '', doc)\n",
        "    doc = re.sub(r'[0-9]+', '', doc)\n",
        "    doc = re.sub(r'(.)\\1+',r'\\1\\1', doc)\n",
        "    doc = re.sub(r'[\\?\\.\\!]+(?=[\\?.\\!])', '',doc)\n",
        "    doc = re.sub(r'[^a-zA-Z]',' ', doc)\n",
        "    doc = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', doc)\n",
        "    doc = doc.replace('\\n', ' ')\n",
        "    doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
        "    doc = doc.strip(' ')\n",
        "    #Mengubah menjadi huruf kecil\n",
        "    doc = doc.lower()\n",
        "    #Text Normalization\n",
        "    doc = informal_to_formal_indo(doc)\n",
        "    #Punctuation Removal+Menghapus Angka\n",
        "    doc = doc.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
        "    #Whitespace Removal\n",
        "    doc = doc.strip()\n",
        "    #Tokenization\n",
        "    doc = tokenizer.tokenize(doc)\n",
        "    doc_token1 = [word for word in doc]\n",
        "    #Stopwords Removal\n",
        "    doc_token2 = [word for word in doc_token1 if word not in stopword.get_stopword()]\n",
        "    #Lemmatization\n",
        "    doc_token3 = [lemmatizer.lemmatize(word) for word in doc_token2]\n",
        "    return doc_token3"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:16:11.904796Z",
          "iopub.execute_input": "2023-10-13T12:16:11.905104Z",
          "iopub.status.idle": "2023-10-13T12:16:11.913021Z",
          "shell.execute_reply.started": "2023-10-13T12:16:11.905079Z",
          "shell.execute_reply": "2023-10-13T12:16:11.912143Z"
        },
        "trusted": true,
        "id": "I5tENPHrhdJa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#text  pre-processing\n",
        "review['preprocessing'] = review['ulasan'].apply(my_tokenizer)\n",
        "review[['ulasan', 'preprocessing']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:16:11.914206Z",
          "iopub.execute_input": "2023-10-13T12:16:11.914723Z",
          "iopub.status.idle": "2023-10-13T12:16:12.884961Z",
          "shell.execute_reply.started": "2023-10-13T12:16:11.914694Z",
          "shell.execute_reply": "2023-10-13T12:16:12.883898Z"
        },
        "trusted": true,
        "id": "-npea5dvhdJa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "review1=review[['ulasan', 'preprocessing']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:16:12.886293Z",
          "iopub.execute_input": "2023-10-13T12:16:12.886601Z",
          "iopub.status.idle": "2023-10-13T12:16:12.893231Z",
          "shell.execute_reply.started": "2023-10-13T12:16:12.886576Z",
          "shell.execute_reply": "2023-10-13T12:16:12.892247Z"
        },
        "trusted": true,
        "id": "3FKnEoFzhdJa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "\n",
        "def stemming(ulasan) :\n",
        "  factory = StemmerFactory()\n",
        "  stemmer = factory.create_stemmer()\n",
        "  do = []\n",
        "  for w in ulasan:\n",
        "    dt = stemmer.stem(w)\n",
        "    do.append(dt)\n",
        "  d_clean = []\n",
        "  d_clean = \" \".join(do)\n",
        "  return d_clean\n",
        "\n",
        "review['stemming_ulasan'] = review['preprocessing'].apply(stemming)\n",
        "review[['stemming_ulasan']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:16:12.894552Z",
          "iopub.execute_input": "2023-10-13T12:16:12.895262Z",
          "iopub.status.idle": "2023-10-13T12:25:04.986295Z",
          "shell.execute_reply.started": "2023-10-13T12:16:12.895234Z",
          "shell.execute_reply": "2023-10-13T12:25:04.984821Z"
        },
        "trusted": true,
        "id": "QAAsX-NehdJa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Labeling with Inset Lexicon"
      ],
      "metadata": {
        "id": "vphuce0EhdJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lexicon_positive = pd.read_excel('/kaggle/input/kamus-sentimen/kamus_positif.xlsx')\n",
        "lexicon_positive_dict = {}\n",
        "for index, row in lexicon_positive.iterrows():\n",
        "    if row[0] not in lexicon_positive_dict:\n",
        "        lexicon_positive_dict[row[0]] = row[1]\n",
        "\n",
        "lexicon_negative = pd.read_excel('/kaggle/input/kamus-sentimen/kamus_negatif.xlsx')\n",
        "lexicon_negative_dict = {}\n",
        "for index, row in lexicon_negative.iterrows():\n",
        "    if row[0] not in lexicon_negative_dict:\n",
        "        lexicon_negative_dict[row[0]] = row[1]\n",
        "\n",
        "def sentiment_analysis_lexicon_indonesia(ulasan):\n",
        "    score = 0\n",
        "    for word in ulasan:\n",
        "        if (word in lexicon_positive_dict):\n",
        "            score = score + lexicon_positive_dict[word]\n",
        "    for word in ulasan:\n",
        "        if (word in lexicon_negative_dict):\n",
        "            score = score + lexicon_negative_dict[word]\n",
        "    sentimen=''\n",
        "    if (score > 0):\n",
        "        sentimen = 'positif'\n",
        "    elif (score < 0):\n",
        "        sentimen = 'negatif'\n",
        "    else:\n",
        "        sentimen = 'netral'\n",
        "    return score, sentimen\n",
        "\n",
        "results = review['preprocessing'].apply(sentiment_analysis_lexicon_indonesia)\n",
        "results = list(zip(*results))\n",
        "review['label'] = results[0]\n",
        "#data['sentimen'] = results[1]\n",
        "#data\n",
        "\n",
        "review['label'] = results[1]\n",
        "dataSentimen = review\n",
        "data_inset = review\n",
        "\n",
        "data_inset[['ulasan', 'preprocessing', 'label']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:04.988441Z",
          "iopub.execute_input": "2023-10-13T12:25:04.988831Z",
          "iopub.status.idle": "2023-10-13T12:25:06.051132Z",
          "shell.execute_reply.started": "2023-10-13T12:25:04.9888Z",
          "shell.execute_reply": "2023-10-13T12:25:06.049977Z"
        },
        "trusted": true,
        "id": "jUrSJzb-hdJf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data = review[['stemming_ulasan', 'label']]\n",
        "data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:06.053013Z",
          "iopub.execute_input": "2023-10-13T12:25:06.053515Z",
          "iopub.status.idle": "2023-10-13T12:25:06.068277Z",
          "shell.execute_reply.started": "2023-10-13T12:25:06.053484Z",
          "shell.execute_reply": "2023-10-13T12:25:06.067185Z"
        },
        "trusted": true,
        "id": "o22ki-XrhdJg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:06.070148Z",
          "iopub.execute_input": "2023-10-13T12:25:06.070517Z",
          "iopub.status.idle": "2023-10-13T12:25:06.09085Z",
          "shell.execute_reply.started": "2023-10-13T12:25:06.070486Z",
          "shell.execute_reply": "2023-10-13T12:25:06.089923Z"
        },
        "trusted": true,
        "id": "0RXYlPlbhdJg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'].value_counts().plot.pie(autopct='%.2f')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:06.092037Z",
          "iopub.execute_input": "2023-10-13T12:25:06.092475Z",
          "iopub.status.idle": "2023-10-13T12:25:06.321309Z",
          "shell.execute_reply.started": "2023-10-13T12:25:06.092444Z",
          "shell.execute_reply": "2023-10-13T12:25:06.320158Z"
        },
        "trusted": true,
        "id": "36L7SbyvhdJh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data.replace(to_replace='negatif', value=0, inplace=True)\n",
        "data.replace(to_replace='positif', value=1, inplace=True)\n",
        "data.replace(to_replace='netral', value=2, inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:06.323418Z",
          "iopub.execute_input": "2023-10-13T12:25:06.324326Z",
          "iopub.status.idle": "2023-10-13T12:25:06.353733Z",
          "shell.execute_reply.started": "2023-10-13T12:25:06.32428Z",
          "shell.execute_reply": "2023-10-13T12:25:06.352073Z"
        },
        "trusted": true,
        "id": "IjPW1hFPhdJh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Data"
      ],
      "metadata": {
        "id": "TEdouqoBhdJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(data, test_size=0.2)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5)\n",
        "df_train.shape, df_test.shape, df_val.shape\n",
        "print('Training data shape:', df_train.shape)\n",
        "print('Validation data shape:', df_val.shape)\n",
        "print('Test data shape:', df_test.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:06.367843Z",
          "iopub.execute_input": "2023-10-13T12:25:06.370023Z",
          "iopub.status.idle": "2023-10-13T12:25:06.383338Z",
          "shell.execute_reply.started": "2023-10-13T12:25:06.369932Z",
          "shell.execute_reply": "2023-10-13T12:25:06.38233Z"
        },
        "trusted": true,
        "id": "E-uTGOPGhdJh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.countplot(x=df_train['label'])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:06.384837Z",
          "iopub.execute_input": "2023-10-13T12:25:06.385565Z",
          "iopub.status.idle": "2023-10-13T12:25:06.898296Z",
          "shell.execute_reply.started": "2023-10-13T12:25:06.385534Z",
          "shell.execute_reply": "2023-10-13T12:25:06.896636Z"
        },
        "trusted": true,
        "id": "Iz45Fs6chdJi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.to_csv('data_training.csv', index = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:06.901306Z",
          "iopub.execute_input": "2023-10-13T12:25:06.902638Z",
          "iopub.status.idle": "2023-10-13T12:25:06.920264Z",
          "shell.execute_reply.started": "2023-10-13T12:25:06.902566Z",
          "shell.execute_reply": "2023-10-13T12:25:06.919299Z"
        },
        "trusted": true,
        "id": "iYhkM5oXhdJi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data_training.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:06.921637Z",
          "iopub.execute_input": "2023-10-13T12:25:06.922223Z",
          "iopub.status.idle": "2023-10-13T12:25:06.937415Z",
          "shell.execute_reply.started": "2023-10-13T12:25:06.922192Z",
          "shell.execute_reply": "2023-10-13T12:25:06.936505Z"
        },
        "trusted": true,
        "id": "R0tu-4ZJhdJi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.countplot(x=df_val['label'])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:06.938608Z",
          "iopub.execute_input": "2023-10-13T12:25:06.939982Z",
          "iopub.status.idle": "2023-10-13T12:25:07.149392Z",
          "shell.execute_reply.started": "2023-10-13T12:25:06.939934Z",
          "shell.execute_reply": "2023-10-13T12:25:07.148196Z"
        },
        "trusted": true,
        "id": "K_LIfHkWhdJi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.to_csv('data_validasi.csv', index = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:07.151017Z",
          "iopub.execute_input": "2023-10-13T12:25:07.15203Z",
          "iopub.status.idle": "2023-10-13T12:25:07.158903Z",
          "shell.execute_reply.started": "2023-10-13T12:25:07.15199Z",
          "shell.execute_reply": "2023-10-13T12:25:07.157626Z"
        },
        "trusted": true,
        "id": "89erMjsjhdJj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data_validasi.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:07.160202Z",
          "iopub.execute_input": "2023-10-13T12:25:07.160618Z",
          "iopub.status.idle": "2023-10-13T12:25:07.185578Z",
          "shell.execute_reply.started": "2023-10-13T12:25:07.160553Z",
          "shell.execute_reply": "2023-10-13T12:25:07.184709Z"
        },
        "trusted": true,
        "id": "I6kXX7mUhdJj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.countplot(x=df_test['label'])\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:07.186911Z",
          "iopub.execute_input": "2023-10-13T12:25:07.187955Z",
          "iopub.status.idle": "2023-10-13T12:25:07.396935Z",
          "shell.execute_reply.started": "2023-10-13T12:25:07.187923Z",
          "shell.execute_reply": "2023-10-13T12:25:07.395539Z"
        },
        "trusted": true,
        "id": "JBhIxz84hdJp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.to_csv('data_testing.csv', index = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:07.398079Z",
          "iopub.execute_input": "2023-10-13T12:25:07.398429Z",
          "iopub.status.idle": "2023-10-13T12:25:07.405532Z",
          "shell.execute_reply.started": "2023-10-13T12:25:07.398401Z",
          "shell.execute_reply": "2023-10-13T12:25:07.404538Z"
        },
        "trusted": true,
        "id": "VUgcO-QphdJp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data_testing.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:07.406717Z",
          "iopub.execute_input": "2023-10-13T12:25:07.407485Z",
          "iopub.status.idle": "2023-10-13T12:25:07.42827Z",
          "shell.execute_reply.started": "2023-10-13T12:25:07.407451Z",
          "shell.execute_reply": "2023-10-13T12:25:07.427093Z"
        },
        "trusted": true,
        "id": "KYe9_u4UhdJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indobert Model"
      ],
      "metadata": {
        "id": "dNT-DCrmhdJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelling\n",
        "!pip install transformers"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:07.430849Z",
          "iopub.execute_input": "2023-10-13T12:25:07.431644Z",
          "iopub.status.idle": "2023-10-13T12:25:18.402465Z",
          "shell.execute_reply.started": "2023-10-13T12:25:07.431609Z",
          "shell.execute_reply": "2023-10-13T12:25:18.400902Z"
        },
        "trusted": true,
        "id": "DkV3XePPhdJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load tokenizer dari pre-trained model\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p2')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:18.404414Z",
          "iopub.execute_input": "2023-10-13T12:25:18.40482Z",
          "iopub.status.idle": "2023-10-13T12:25:22.07581Z",
          "shell.execute_reply.started": "2023-10-13T12:25:18.404785Z",
          "shell.execute_reply": "2023-10-13T12:25:22.0744Z"
        },
        "trusted": true,
        "id": "D7fevOJwhdJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# View vocabulary from pre-trained models that have been preloaded\n",
        "vocabulary = bert_tokenizer.get_vocab()\n",
        "print('Panjang vocabulary:', len(vocabulary))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:22.077315Z",
          "iopub.execute_input": "2023-10-13T12:25:22.078688Z",
          "iopub.status.idle": "2023-10-13T12:25:22.097638Z",
          "shell.execute_reply.started": "2023-10-13T12:25:22.07861Z",
          "shell.execute_reply": "2023-10-13T12:25:22.096184Z"
        },
        "trusted": true,
        "id": "lAX6sanWhdJr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocabulary)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:22.099304Z",
          "iopub.execute_input": "2023-10-13T12:25:22.099651Z",
          "iopub.status.idle": "2023-10-13T12:25:22.150061Z",
          "shell.execute_reply.started": "2023-10-13T12:25:22.099624Z",
          "shell.execute_reply": "2023-10-13T12:25:22.148888Z"
        },
        "trusted": true,
        "id": "QJtWl1wshdJr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of Tokenization\n",
        "# Retrieve the 1st index data on the dataframe\n",
        "print('Kalimat:', review['stemming_ulasan'][0])\n",
        "print('BERT Tokenizer:', bert_tokenizer.tokenize(review['stemming_ulasan'][0]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:22.151451Z",
          "iopub.execute_input": "2023-10-13T12:25:22.151983Z",
          "iopub.status.idle": "2023-10-13T12:25:22.159155Z",
          "shell.execute_reply.started": "2023-10-13T12:25:22.151952Z",
          "shell.execute_reply": "2023-10-13T12:25:22.158292Z"
        },
        "trusted": true,
        "id": "hMHDLIfPhdJr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of input formatting for BERT.\n",
        "# Input formatting can use 'encode_plus' function\n",
        "bert_input = bert_tokenizer.encode_plus(\n",
        "    # Sample sentences\n",
        "    review['stemming_ulasan'][0],\n",
        "    # Add [CLS] token at the beginning of the sentence & [SEP] token at the end of the sentence\n",
        "    add_special_tokens = True,\n",
        "    # Add padding to max_length using [PAD] token\n",
        "    # jika kalimat kurang dari max_length\n",
        "    padding = 'max_length',\n",
        "    # Truncate if sentence is more than max_length\n",
        "    truncation = 'longest_first',\n",
        "    # Determine the max_length of the entire sentence\n",
        "    max_length = 50,\n",
        "    # Returns the attention mask value\n",
        "    return_attention_mask = True,\n",
        "    # Returns the value of token type id (segment embedding)\n",
        "    return_token_type_ids =True)\n",
        "# The function 'encode_plus' returns 3 values:\n",
        "# input_ids, token_type_ids, attention_mask\n",
        "bert_input.keys()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:22.16059Z",
          "iopub.execute_input": "2023-10-13T12:25:22.161204Z",
          "iopub.status.idle": "2023-10-13T12:25:22.176102Z",
          "shell.execute_reply.started": "2023-10-13T12:25:22.161153Z",
          "shell.execute_reply": "2023-10-13T12:25:22.175173Z"
        },
        "trusted": true,
        "id": "qYrR1FzPhdJs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Original data\n",
        "print('Kalimat\\t\\t:', review['stemming_ulasan'][0]) #1 denotes first order data or first review data\n",
        "                                                   # so for example I change it to 1000 still 1 data appears but the order is 1000th\n",
        "# Input formatting + tokenizer return\n",
        "print('Tokenizer\\t:', bert_tokenizer.convert_ids_to_tokens(bert_input['input_ids']))\n",
        "# Input IDs: token indexes in the tokenizer vocabulary\n",
        "print('Input IDs\\t:', bert_input['input_ids'])\n",
        "# Token type IDs: shows the sequence of sentences in the sequence (segment embedding)\n",
        "print('Token Type IDs\\t:', bert_input['token_type_ids'])\n",
        "# Attention mask : returns value [0,1].\n",
        "#1 means masked token, 0 tokens are not masked (ignored)\n",
        "print('Attention Mask\\t:', bert_input['attention_mask'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:22.177605Z",
          "iopub.execute_input": "2023-10-13T12:25:22.178399Z",
          "iopub.status.idle": "2023-10-13T12:25:22.196849Z",
          "shell.execute_reply.started": "2023-10-13T12:25:22.178364Z",
          "shell.execute_reply": "2023-10-13T12:25:22.196029Z"
        },
        "trusted": true,
        "id": "BjdhtVALhdJt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# There are many ways to define max_length\n",
        "# The intuition is that we don't want to cut sentences\n",
        "# Or added too much padding (longer computation)\n",
        "\n",
        "# In this example, max_length is determined from the distribution of tokens in the dataset\n",
        "token_lens = []\n",
        "for txt in review['stemming_ulasan']:\n",
        "  tokens = bert_tokenizer.encode(txt)\n",
        "  token_lens.append(len(tokens))\n",
        "sns.histplot(token_lens, kde=True, stat='density', linewidth=0)\n",
        "plt.xlim([0, 100]);\n",
        "plt.xlabel('Token count');"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:22.198541Z",
          "iopub.execute_input": "2023-10-13T12:25:22.199394Z",
          "iopub.status.idle": "2023-10-13T12:25:23.165287Z",
          "shell.execute_reply.started": "2023-10-13T12:25:22.199344Z",
          "shell.execute_reply": "2023-10-13T12:25:23.164372Z"
        },
        "trusted": true,
        "id": "V6nbJBIvhdJt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to combine tokenization steps\n",
        "# Added special tokens for all data as input formatting to the BERT model\n",
        "def convert_example_to_feature(sentence):\n",
        "  return bert_tokenizer.encode_plus(\n",
        "      sentence,\n",
        "      add_special_tokens=True,\n",
        "      padding='max_length',\n",
        "      truncation='longest_first',\n",
        "      max_length=42,\n",
        "      return_attention_mask=True,\n",
        "      return_token_type_ids=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:23.166352Z",
          "iopub.execute_input": "2023-10-13T12:25:23.166918Z",
          "iopub.status.idle": "2023-10-13T12:25:23.17247Z",
          "shell.execute_reply.started": "2023-10-13T12:25:23.166886Z",
          "shell.execute_reply": "2023-10-13T12:25:23.171198Z"
        },
        "trusted": true,
        "id": "6efE2sG2hdJu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to map input formatting results to match the BERT model\n",
        "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
        "  return {\n",
        "      \"input_ids\": input_ids,               # Sebagai token embedding\n",
        "      \"token_type_ids\": token_type_ids,     # Sebagai segment embedding\n",
        "      \"attention_mask\": attention_masks,    # Sebagai filter informasi mana yang kalkulasi oleh model\n",
        "  }, label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:23.174158Z",
          "iopub.execute_input": "2023-10-13T12:25:23.17505Z",
          "iopub.status.idle": "2023-10-13T12:25:23.189897Z",
          "shell.execute_reply.started": "2023-10-13T12:25:23.175005Z",
          "shell.execute_reply": "2023-10-13T12:25:23.188265Z"
        },
        "trusted": true,
        "id": "ZSvU0Se-hdJu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Create a function to iterate or encode each sentence in the entire data\n",
        "def encode(data):\n",
        "  input_ids_list = []\n",
        "  token_type_ids_list = []\n",
        "  attention_mask_list = []\n",
        "  label_list = []\n",
        "\n",
        "  for sentence, label in data.to_numpy():\n",
        "    bert_input = convert_example_to_feature(sentence)\n",
        "    input_ids_list.append(bert_input['input_ids'])\n",
        "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "    attention_mask_list.append(bert_input['attention_mask'])\n",
        "    label_list.append([label])\n",
        "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:23.19155Z",
          "iopub.execute_input": "2023-10-13T12:25:23.192068Z",
          "iopub.status.idle": "2023-10-13T12:25:31.818658Z",
          "shell.execute_reply.started": "2023-10-13T12:25:23.192023Z",
          "shell.execute_reply": "2023-10-13T12:25:31.817538Z"
        },
        "trusted": true,
        "id": "14mD_A2zhdJu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform input formatting using the previous function on the data as a whole\n",
        "train_encoded = encode(df_train).batch(32)\n",
        "test_encoded = encode(df_test).batch(32)\n",
        "val_encoded = encode(df_val).batch(32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:31.820093Z",
          "iopub.execute_input": "2023-10-13T12:25:31.820882Z",
          "iopub.status.idle": "2023-10-13T12:25:32.838796Z",
          "shell.execute_reply.started": "2023-10-13T12:25:31.820847Z",
          "shell.execute_reply": "2023-10-13T12:25:32.837524Z"
        },
        "trusted": true,
        "id": "57G5ddxOhdJv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "# Load model\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained(\n",
        "    'indobenchmark/indobert-base-p2', num_labels=3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:32.840314Z",
          "iopub.execute_input": "2023-10-13T12:25:32.840661Z",
          "iopub.status.idle": "2023-10-13T12:25:43.283409Z",
          "shell.execute_reply.started": "2023-10-13T12:25:32.840633Z",
          "shell.execute_reply": "2023-10-13T12:25:43.282265Z"
        },
        "trusted": true,
        "id": "k3O7BrW4hdJv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "bert_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00003),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=tf.keras.metrics.SparseCategoricalAccuracy('accuracy'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:43.284862Z",
          "iopub.execute_input": "2023-10-13T12:25:43.285176Z",
          "iopub.status.idle": "2023-10-13T12:25:43.312496Z",
          "shell.execute_reply.started": "2023-10-13T12:25:43.285149Z",
          "shell.execute_reply": "2023-10-13T12:25:43.311249Z"
        },
        "trusted": true,
        "id": "minDazqHhdJv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "bert_history = bert_model.fit(train_encoded, epochs=5,\n",
        "                              batch_size=32, validation_data=val_encoded)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:25:43.314108Z",
          "iopub.execute_input": "2023-10-13T12:25:43.31469Z",
          "iopub.status.idle": "2023-10-13T12:45:17.638388Z",
          "shell.execute_reply.started": "2023-10-13T12:25:43.31464Z",
          "shell.execute_reply": "2023-10-13T12:45:17.63672Z"
        },
        "trusted": true,
        "id": "hQYzQuzJhdJw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function for plotting training results\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:17.640843Z",
          "iopub.execute_input": "2023-10-13T12:45:17.641254Z",
          "iopub.status.idle": "2023-10-13T12:45:17.647148Z",
          "shell.execute_reply.started": "2023-10-13T12:45:17.641222Z",
          "shell.execute_reply": "2023-10-13T12:45:17.646273Z"
        },
        "trusted": true,
        "id": "3owHcACUhdJw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graphs(bert_history, 'accuracy')\n",
        "plot_graphs(bert_history, 'loss')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:17.648469Z",
          "iopub.execute_input": "2023-10-13T12:45:17.649011Z",
          "iopub.status.idle": "2023-10-13T12:45:18.066992Z",
          "shell.execute_reply.started": "2023-10-13T12:45:17.648981Z",
          "shell.execute_reply": "2023-10-13T12:45:18.065814Z"
        },
        "trusted": true,
        "id": "Ga7xlMfehdJw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nEpoch No.  Train Accuracy  Train Loss      Val Accuracy    Val Loss')\n",
        "for i in range(5):\n",
        "  print('{:8d} {:10f} \\t {:10f} \\t {:10f} \\t {:10f}'.format(i + 1, bert_history.history['accuracy'][i],\n",
        "                                                            bert_history.history['loss'][i],\n",
        "                                                            bert_history.history['val_accuracy'][i],\n",
        "                                                            bert_history.history['val_loss'][i]))\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:18.068662Z",
          "iopub.execute_input": "2023-10-13T12:45:18.06912Z",
          "iopub.status.idle": "2023-10-13T12:45:18.07723Z",
          "shell.execute_reply.started": "2023-10-13T12:45:18.069083Z",
          "shell.execute_reply": "2023-10-13T12:45:18.075967Z"
        },
        "trusted": true,
        "id": "ecpuL5EhhdJx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model.save_weights('bert-model.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:18.07872Z",
          "iopub.execute_input": "2023-10-13T12:45:18.079775Z",
          "iopub.status.idle": "2023-10-13T12:45:19.024185Z",
          "shell.execute_reply.started": "2023-10-13T12:45:18.079722Z",
          "shell.execute_reply": "2023-10-13T12:45:19.0227Z"
        },
        "trusted": true,
        "id": "C31w_KaGhdJx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "score = bert_model.evaluate(test_encoded)\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:19.025972Z",
          "iopub.execute_input": "2023-10-13T12:45:19.026331Z",
          "iopub.status.idle": "2023-10-13T12:45:29.292782Z",
          "shell.execute_reply.started": "2023-10-13T12:45:19.026304Z",
          "shell.execute_reply": "2023-10-13T12:45:29.291646Z"
        },
        "trusted": true,
        "id": "xXqanVM7hdJx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_raw = bert_model.predict(test_encoded)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:29.296726Z",
          "iopub.execute_input": "2023-10-13T12:45:29.297163Z",
          "iopub.status.idle": "2023-10-13T12:45:43.273273Z",
          "shell.execute_reply.started": "2023-10-13T12:45:29.297127Z",
          "shell.execute_reply": "2023-10-13T12:45:43.272031Z"
        },
        "trusted": true,
        "id": "u9nqvNzrhdJx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(predicted_raw['logits'], axis=1)\n",
        "y_true = np.array(df_test['label'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:43.275607Z",
          "iopub.execute_input": "2023-10-13T12:45:43.27615Z",
          "iopub.status.idle": "2023-10-13T12:45:43.282619Z",
          "shell.execute_reply.started": "2023-10-13T12:45:43.276101Z",
          "shell.execute_reply": "2023-10-13T12:45:43.281165Z"
        },
        "trusted": true,
        "id": "4dAiuKZEhdJy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "accuracy_score(y_true, y_pred)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:43.284796Z",
          "iopub.execute_input": "2023-10-13T12:45:43.285987Z",
          "iopub.status.idle": "2023-10-13T12:45:43.304299Z",
          "shell.execute_reply.started": "2023-10-13T12:45:43.285947Z",
          "shell.execute_reply": "2023-10-13T12:45:43.303017Z"
        },
        "trusted": true,
        "id": "fV-H6agqhdJy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:43.306143Z",
          "iopub.execute_input": "2023-10-13T12:45:43.306896Z",
          "iopub.status.idle": "2023-10-13T12:45:43.326857Z",
          "shell.execute_reply.started": "2023-10-13T12:45:43.306847Z",
          "shell.execute_reply": "2023-10-13T12:45:43.325947Z"
        },
        "trusted": true,
        "id": "LWHhJKXEhdJz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:43.328707Z",
          "iopub.execute_input": "2023-10-13T12:45:43.329713Z",
          "iopub.status.idle": "2023-10-13T12:45:43.343168Z",
          "shell.execute_reply.started": "2023-10-13T12:45:43.329648Z",
          "shell.execute_reply": "2023-10-13T12:45:43.342152Z"
        },
        "trusted": true,
        "id": "CVL2nPS_hdJz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load fine-tuning results\n",
        "bert_load_model = TFBertForSequenceClassification.from_pretrained(\n",
        "    'indobenchmark/indobert-base-p2', num_labels=3)\n",
        "bert_load_model.load_weights('bert-model.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:43.344874Z",
          "iopub.execute_input": "2023-10-13T12:45:43.34543Z",
          "iopub.status.idle": "2023-10-13T12:45:47.696822Z",
          "shell.execute_reply.started": "2023-10-13T12:45:43.345398Z",
          "shell.execute_reply": "2023-10-13T12:45:47.695559Z"
        },
        "trusted": true,
        "id": "cGcUTKqlhdJ0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "input_text = 'tolong dong diupgrade untuk di tambah riwayat penggunaan listrik harian supaya kita bisa lebih mudah lagi mengontrol penggunaan listrik setiap harinya terimakasih'\n",
        "\n",
        "# Encode input text\n",
        "input_text_tokenized = bert_tokenizer.encode(input_text,\n",
        "                                             truncation=True,\n",
        "                                             padding='max_length',\n",
        "                                             return_tensors='tf')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:47.698606Z",
          "iopub.execute_input": "2023-10-13T12:45:47.69907Z",
          "iopub.status.idle": "2023-10-13T12:45:47.711837Z",
          "shell.execute_reply.started": "2023-10-13T12:45:47.699036Z",
          "shell.execute_reply": "2023-10-13T12:45:47.71066Z"
        },
        "trusted": true,
        "id": "ZV7YHT2MhdJ0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "bert_predict = bert_load_model(input_text_tokenized)\n",
        "# Softmax function to get classification results\n",
        "bert_output = tf.nn.softmax(bert_predict[0], axis=-1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:47.713445Z",
          "iopub.execute_input": "2023-10-13T12:45:47.713874Z",
          "iopub.status.idle": "2023-10-13T12:45:48.122574Z",
          "shell.execute_reply.started": "2023-10-13T12:45:47.713839Z",
          "shell.execute_reply": "2023-10-13T12:45:48.121251Z"
        },
        "trusted": true,
        "id": "-S5--1mXhdJ0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_labels = ['netral','negatif', 'positif']\n",
        "label = tf.argmax(bert_output, axis=1)\n",
        "label = label.numpy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:48.124385Z",
          "iopub.execute_input": "2023-10-13T12:45:48.124907Z",
          "iopub.status.idle": "2023-10-13T12:45:48.132748Z",
          "shell.execute_reply.started": "2023-10-13T12:45:48.124862Z",
          "shell.execute_reply": "2023-10-13T12:45:48.131473Z"
        },
        "trusted": true,
        "id": "qYvCry-KhdJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_text, ':', sentiment_labels[label[0]])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:48.144156Z",
          "iopub.execute_input": "2023-10-13T12:45:48.144589Z",
          "iopub.status.idle": "2023-10-13T12:45:48.152518Z",
          "shell.execute_reply.started": "2023-10-13T12:45:48.144561Z",
          "shell.execute_reply": "2023-10-13T12:45:48.151234Z"
        },
        "trusted": true,
        "id": "KMdvRfaUhdJ1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "REFX7DBehdJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "from pandas import DataFrame\n",
        "confm = confusion_matrix(y_true, y_pred)\n",
        "columns = ['negatif','positif','netral']\n",
        "df_cm = DataFrame(confm, index=columns, columns=columns)\n",
        "ax = sn.heatmap(df_cm, cmap='Blues', annot=True)\n",
        "ax.set_title('Confusion matrix')\n",
        "ax.set_xlabel('Label prediksi')\n",
        "ax.set_ylabel('Label sebenarnya')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:48.153808Z",
          "iopub.execute_input": "2023-10-13T12:45:48.1542Z",
          "iopub.status.idle": "2023-10-13T12:45:48.501951Z",
          "shell.execute_reply.started": "2023-10-13T12:45:48.154169Z",
          "shell.execute_reply": "2023-10-13T12:45:48.500694Z"
        },
        "trusted": true,
        "id": "rfIO3BnShdJ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WordCloud"
      ],
      "metadata": {
        "id": "qTetaRA8hdJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_GROUPBY_label = data_inset.groupby(\"label\", sort=False)\n",
        "df_GROUPBY_label.get_group('positif')\n",
        "datagroup = df_GROUPBY_label[['preprocessing','label']].get_group('positif')\n",
        "datagroup.to_csv('positif.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:48.503878Z",
          "iopub.execute_input": "2023-10-13T12:45:48.504241Z",
          "iopub.status.idle": "2023-10-13T12:45:48.52757Z",
          "shell.execute_reply.started": "2023-10-13T12:45:48.504214Z",
          "shell.execute_reply": "2023-10-13T12:45:48.526353Z"
        },
        "trusted": true,
        "id": "DTwyuNf7hdJ2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "positif = pd.read_csv('positif.csv')\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, ImageColorGenerator\n",
        "allWords = ' '.join([twts for twts in  positif['preprocessing']])\n",
        "wordCloud = WordCloud(colormap=\"viridis\",background_color='white',\n",
        "                       width=800, height=800, random_state=10, max_font_size=200, min_font_size=20).generate(allWords)\n",
        "\n",
        "plt.figure( figsize=(10,5), facecolor='k', frameon=False)\n",
        "plt.imshow(wordCloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:48.529165Z",
          "iopub.execute_input": "2023-10-13T12:45:48.529636Z",
          "iopub.status.idle": "2023-10-13T12:45:49.551891Z",
          "shell.execute_reply.started": "2023-10-13T12:45:48.529606Z",
          "shell.execute_reply": "2023-10-13T12:45:49.550202Z"
        },
        "trusted": true,
        "id": "k3ydQsSUhdJ3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_GROUPBY_label = data_inset.groupby(\"label\", sort=False)\n",
        "df_GROUPBY_label.get_group('negatif')\n",
        "datagroup = df_GROUPBY_label[['preprocessing','label']].get_group('negatif')\n",
        "datagroup.to_csv('negatif.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:49.553896Z",
          "iopub.execute_input": "2023-10-13T12:45:49.554763Z",
          "iopub.status.idle": "2023-10-13T12:45:49.569996Z",
          "shell.execute_reply.started": "2023-10-13T12:45:49.554723Z",
          "shell.execute_reply": "2023-10-13T12:45:49.56849Z"
        },
        "trusted": true,
        "id": "6sHFIKdAhdJ3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "negatif = pd.read_csv('negatif.csv')\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, ImageColorGenerator\n",
        "allWords = ' '.join([twts for twts in  negatif['preprocessing']])\n",
        "wordCloud = WordCloud(colormap=\"viridis\", background_color='white',\n",
        "                       width=800, height=800, random_state=10, max_font_size=200, min_font_size=20).generate(allWords)\n",
        "\n",
        "plt.figure( figsize=(10,5), facecolor='k', frameon=False)\n",
        "plt.imshow(wordCloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:49.571713Z",
          "iopub.execute_input": "2023-10-13T12:45:49.572901Z",
          "iopub.status.idle": "2023-10-13T12:45:50.288122Z",
          "shell.execute_reply.started": "2023-10-13T12:45:49.572863Z",
          "shell.execute_reply": "2023-10-13T12:45:50.286904Z"
        },
        "trusted": true,
        "id": "bN3u0_qJhdJ3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_GROUPBY_label = data_inset.groupby(\"label\", sort=False)\n",
        "df_GROUPBY_label.get_group('netral')\n",
        "datagroup = df_GROUPBY_label[['preprocessing','label']].get_group('netral')\n",
        "datagroup.to_csv('netral.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:50.289773Z",
          "iopub.execute_input": "2023-10-13T12:45:50.290349Z",
          "iopub.status.idle": "2023-10-13T12:45:50.3054Z",
          "shell.execute_reply.started": "2023-10-13T12:45:50.290313Z",
          "shell.execute_reply": "2023-10-13T12:45:50.304105Z"
        },
        "trusted": true,
        "id": "0IVB9RRJhdJ3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "netral = pd.read_csv('netral.csv')\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, ImageColorGenerator\n",
        "allWords = ' '.join([twts for twts in  netral['preprocessing']])\n",
        "wordCloud = WordCloud(colormap=\"viridis\", background_color='white',\n",
        "                       width=800, height=800, random_state=200, max_font_size=200, min_font_size=20).generate(allWords)\n",
        "\n",
        "plt.figure( figsize=(10,5), facecolor='k', frameon=False)\n",
        "plt.imshow(wordCloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:50.307173Z",
          "iopub.execute_input": "2023-10-13T12:45:50.308487Z",
          "iopub.status.idle": "2023-10-13T12:45:51.100815Z",
          "shell.execute_reply.started": "2023-10-13T12:45:50.308452Z",
          "shell.execute_reply": "2023-10-13T12:45:51.099469Z"
        },
        "trusted": true,
        "id": "pK4trqPkhdJ4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya kita akan melakukan analisis sentimen ulasan movie menggunakan beberapa lexicon bahasa inggris."
      ],
      "metadata": {
        "id": "ZkiGWCpthdJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:51.10226Z",
          "iopub.execute_input": "2023-10-13T12:45:51.102609Z",
          "iopub.status.idle": "2023-10-13T12:45:51.367178Z",
          "shell.execute_reply.started": "2023-10-13T12:45:51.10258Z",
          "shell.execute_reply": "2023-10-13T12:45:51.365912Z"
        },
        "trusted": true,
        "id": "-sqWdL-mhdJ4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import textblob\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "np.set_printoptions(precision=2, linewidth=80)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:51.368814Z",
          "iopub.execute_input": "2023-10-13T12:45:51.369462Z",
          "iopub.status.idle": "2023-10-13T12:45:51.421062Z",
          "shell.execute_reply.started": "2023-10-13T12:45:51.369422Z",
          "shell.execute_reply": "2023-10-13T12:45:51.419725Z"
        },
        "trusted": true,
        "id": "-ll6jY6HhdJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install text_normalizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:45:51.422528Z",
          "iopub.execute_input": "2023-10-13T12:45:51.422917Z",
          "iopub.status.idle": "2023-10-13T12:46:06.779815Z",
          "shell.execute_reply.started": "2023-10-13T12:45:51.422886Z",
          "shell.execute_reply": "2023-10-13T12:46:06.778321Z"
        },
        "trusted": true,
        "id": "khmCz9DbhdJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import text_normalizer as tn"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:06.782061Z",
          "iopub.execute_input": "2023-10-13T12:46:06.782592Z",
          "iopub.status.idle": "2023-10-13T12:46:06.793815Z",
          "shell.execute_reply.started": "2023-10-13T12:46:06.782536Z",
          "shell.execute_reply": "2023-10-13T12:46:06.792579Z"
        },
        "trusted": true,
        "id": "n_p62seBhdJ5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/kaggle/input/movie-review/movie_reviews.csv.bz2', compression='bz2')\n",
        "dataset.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:06.795882Z",
          "iopub.execute_input": "2023-10-13T12:46:06.796352Z",
          "iopub.status.idle": "2023-10-13T12:46:13.236401Z",
          "shell.execute_reply.started": "2023-10-13T12:46:06.796309Z",
          "shell.execute_reply": "2023-10-13T12:46:13.235243Z"
        },
        "trusted": true,
        "id": "gcFgwfexhdJ6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# extract data for model evaluation\n",
        "reviews = np.array(dataset['review'])\n",
        "sentiments = np.array(dataset['sentiment'])\n",
        "test_reviews = reviews[35000:]\n",
        "test_sentiments = sentiments[35000:]\n",
        "sample_review_ids = [7626, 3533, 13010]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:13.237781Z",
          "iopub.execute_input": "2023-10-13T12:46:13.238185Z",
          "iopub.status.idle": "2023-10-13T12:46:13.246591Z",
          "shell.execute_reply.started": "2023-10-13T12:46:13.238103Z",
          "shell.execute_reply": "2023-10-13T12:46:13.245182Z"
        },
        "trusted": true,
        "id": "PH7IPbLjhdJ6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Textblob Lexicon"
      ],
      "metadata": {
        "id": "92a5t6P9hdJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    print('Predicted Sentiment polarity:', textblob.TextBlob(review).sentiment.polarity)\n",
        "    print('-'*60)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:13.248278Z",
          "iopub.execute_input": "2023-10-13T12:46:13.248765Z",
          "iopub.status.idle": "2023-10-13T12:46:13.314906Z",
          "shell.execute_reply.started": "2023-10-13T12:46:13.248721Z",
          "shell.execute_reply": "2023-10-13T12:46:13.313474Z"
        },
        "trusted": true,
        "id": "EucAvsBRhdJ7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict sentiment for test dataset\n",
        "sentiment_polarity = [textblob.TextBlob(review).sentiment.polarity for review in test_reviews]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:13.316439Z",
          "iopub.execute_input": "2023-10-13T12:46:13.317164Z",
          "iopub.status.idle": "2023-10-13T12:46:35.942397Z",
          "shell.execute_reply.started": "2023-10-13T12:46:13.317129Z",
          "shell.execute_reply": "2023-10-13T12:46:35.941016Z"
        },
        "trusted": true,
        "id": "pzgYkkS2hdJ7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_sentiments = ['positive' if score >= 0.1 else 'negative' for score in sentiment_polarity]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:35.944065Z",
          "iopub.execute_input": "2023-10-13T12:46:35.94451Z",
          "iopub.status.idle": "2023-10-13T12:46:35.951632Z",
          "shell.execute_reply.started": "2023-10-13T12:46:35.94448Z",
          "shell.execute_reply": "2023-10-13T12:46:35.950122Z"
        },
        "trusted": true,
        "id": "uG5LylADhdJ7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['negative', 'positive']\n",
        "print(classification_report(test_sentiments, predicted_sentiments))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, predicted_sentiments), index=labels, columns=labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:35.953099Z",
          "iopub.execute_input": "2023-10-13T12:46:35.95347Z",
          "iopub.status.idle": "2023-10-13T12:46:36.566342Z",
          "shell.execute_reply.started": "2023-10-13T12:46:35.953442Z",
          "shell.execute_reply": "2023-10-13T12:46:36.565068Z"
        },
        "trusted": true,
        "id": "7DbAhnrRhdJ7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Text = test_reviews[sample_review_ids]\n",
        "Real_sentiments = test_sentiments[sample_review_ids]\n",
        "TextBlob_sentiment_polarity = sentiment_polarity[7626], sentiment_polarity[3533],sentiment_polarity[13010]\n",
        "TextBlob_predicted_sentiments = predicted_sentiments[7626],predicted_sentiments[3533],predicted_sentiments[13010]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:36.568237Z",
          "iopub.execute_input": "2023-10-13T12:46:36.568638Z",
          "iopub.status.idle": "2023-10-13T12:46:36.574273Z",
          "shell.execute_reply.started": "2023-10-13T12:46:36.568605Z",
          "shell.execute_reply": "2023-10-13T12:46:36.572983Z"
        },
        "trusted": true,
        "id": "ik6AR0iBhdJ8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "TextBlob_sample_report = {'Text':Text,'Real_sentiments':Real_sentiments,'TextBlob_sentiment_polarity':TextBlob_sentiment_polarity,\n",
        "                          'TextBlob_predicted_sentiments':TextBlob_predicted_sentiments}\n",
        "TextBlob_sample_report = pd.DataFrame(data=TextBlob_sample_report)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:36.576224Z",
          "iopub.execute_input": "2023-10-13T12:46:36.576857Z",
          "iopub.status.idle": "2023-10-13T12:46:36.589246Z",
          "shell.execute_reply.started": "2023-10-13T12:46:36.576806Z",
          "shell.execute_reply": "2023-10-13T12:46:36.587923Z"
        },
        "trusted": true,
        "id": "I6-ttZKjhdJ9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "TextBlob_sample_report"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:36.591057Z",
          "iopub.execute_input": "2023-10-13T12:46:36.591505Z",
          "iopub.status.idle": "2023-10-13T12:46:36.615099Z",
          "shell.execute_reply.started": "2023-10-13T12:46:36.591463Z",
          "shell.execute_reply": "2023-10-13T12:46:36.613979Z"
        },
        "trusted": true,
        "id": "oe2WAym6hdJ9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def color_negative_red(value):\n",
        "  \"\"\"\n",
        "  Colors elements in a dateframe\n",
        "  green if positive and red if\n",
        "  negative. Does not color NaN\n",
        "  values.\n",
        "  \"\"\"\n",
        "\n",
        "  if value == 'positive':\n",
        "    color = 'green'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  return 'color: %s' % color"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:36.617034Z",
          "iopub.execute_input": "2023-10-13T12:46:36.617364Z",
          "iopub.status.idle": "2023-10-13T12:46:36.626011Z",
          "shell.execute_reply.started": "2023-10-13T12:46:36.617338Z",
          "shell.execute_reply": "2023-10-13T12:46:36.625144Z"
        },
        "trusted": true,
        "id": "ZEfdz8hXhdJ-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = TextBlob_sample_report.copy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:36.626961Z",
          "iopub.execute_input": "2023-10-13T12:46:36.627399Z",
          "iopub.status.idle": "2023-10-13T12:46:36.63989Z",
          "shell.execute_reply.started": "2023-10-13T12:46:36.627363Z",
          "shell.execute_reply": "2023-10-13T12:46:36.638754Z"
        },
        "trusted": true,
        "id": "9eadYmnHhdJ-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.style.applymap(color_negative_red, subset=['Real_sentiments','TextBlob_predicted_sentiments'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:36.641632Z",
          "iopub.execute_input": "2023-10-13T12:46:36.642715Z",
          "iopub.status.idle": "2023-10-13T12:46:36.745917Z",
          "shell.execute_reply.started": "2023-10-13T12:46:36.642651Z",
          "shell.execute_reply": "2023-10-13T12:46:36.744692Z"
        },
        "trusted": true,
        "id": "LfX3SurAhdJ-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(confusion_matrix(test_sentiments, predicted_sentiments),\n",
        "                annot=True,fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
        "\n",
        "plt.title(\"Sentiment Analysis with TextBlob\",fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:36.747664Z",
          "iopub.execute_input": "2023-10-13T12:46:36.748877Z",
          "iopub.status.idle": "2023-10-13T12:46:37.773614Z",
          "shell.execute_reply.started": "2023-10-13T12:46:36.748827Z",
          "shell.execute_reply": "2023-10-13T12:46:37.772339Z"
        },
        "trusted": true,
        "id": "0koXxHJnhdJ-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "TextBlob_model = accuracy_score(test_sentiments, predicted_sentiments)\n",
        "print(TextBlob_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-13T12:46:37.776935Z",
          "iopub.execute_input": "2023-10-13T12:46:37.777287Z",
          "iopub.status.idle": "2023-10-13T12:46:37.826135Z",
          "shell.execute_reply.started": "2023-10-13T12:46:37.77726Z",
          "shell.execute_reply": "2023-10-13T12:46:37.824883Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "3tSSjKxNhdJ_",
        "outputId": "7ef97c40-35c2-4ecf-909d-aa1f20a96976"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_sentiments' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1c579f470037>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTextBlob_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_sentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTextBlob_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_sentiments' is not defined"
          ]
        }
      ],
      "execution_count": 1
    }
  ]
}